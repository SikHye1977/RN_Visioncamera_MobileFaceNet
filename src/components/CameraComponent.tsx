import React, {useEffect, useState} from 'react';
import {
  StyleSheet,
  View,
  Text,
  useWindowDimensions,
  TouchableOpacity,
} from 'react-native';
import {
  Camera,
  useCameraDevice,
  useCameraPermission,
  useFrameProcessor,
} from 'react-native-vision-camera';
import {Face, useFaceDetector} from 'react-native-vision-camera-face-detector';
import {Worklets} from 'react-native-worklets-core';
import {useTensorflowModel} from 'react-native-fast-tflite';
import {useResizePlugin} from 'vision-camera-resize-plugin';

// ğŸ›ï¸ UI ë³´ì •ê°’
const VERTICAL_OFFSET = -50;
const HORIZONTAL_OFFSET = 0;

const CameraComponent = () => {
  const device = useCameraDevice('front');
  const {hasPermission, requestPermission} = useCameraPermission();
  const {width: windowWidth, height: windowHeight} = useWindowDimensions();

  // 1. TFLite ëª¨ë¸ ë¡œë“œ
  const objectDetection = useTensorflowModel(
    require('../assets/MobileFaceNet_new_latest_int8.tflite'),
  );
  const model =
    objectDetection.state === 'loaded' ? objectDetection.model : undefined;

  const {resize} = useResizePlugin();

  // 2. ìƒíƒœ ê´€ë¦¬
  // isCaptured: ì–¼êµ´ì„ ì°¾ì•„ì„œ ë©ˆì·„ëŠ”ì§€ ì—¬ë¶€
  const [isCaptured, setIsCaptured] = useState(false);

  const [faceData, setFaceData] = useState<{
    faces: Face[];
    frameWidth: number;
    frameHeight: number;
    keyString: string;
  }>({faces: [], frameWidth: 0, frameHeight: 0, keyString: ''});

  const {detectFaces} = useFaceDetector({
    performanceMode: 'fast',
    contourMode: 'none',
    landmarkMode: 'none',
    classificationMode: 'none',
  });

  useEffect(() => {
    if (!hasPermission) requestPermission();
  }, [hasPermission]);

  // 3. ë°ì´í„° ì²˜ë¦¬ ë° ìº¡ì²˜ í™•ì • (JS ìŠ¤ë ˆë“œ)
  const handleCaptureJS = Worklets.createRunOnJS(
    (faces: Face[], w: number, h: number, key: string) => {
      // ì´ë¯¸ ìº¡ì²˜ëœ ìƒíƒœë¼ë©´ ë¬´ì‹œ (ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)
      if (key && key.length > 0) {
        setFaceData({faces, frameWidth: w, frameHeight: h, keyString: key});
        setIsCaptured(true); // ì¹´ë©”ë¼ ì •ì§€!
      }
    },
  );

  // 4. í”„ë ˆì„ í”„ë¡œì„¸ì„œ
  const frameProcessor = useFrameProcessor(
    frame => {
      'worklet';

      const faces = detectFaces(frame);

      // ì–¼êµ´ì´ ìˆê³ , ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆì„ ë•Œë§Œ ì‹¤í–‰
      if (faces.length > 0 && model != null) {
        const face = faces[0];

        // ì¢Œí‘œ ë³´ì • (Crash ë°©ì§€)
        const x = Math.max(0, face.bounds.x);
        const y = Math.max(0, face.bounds.y);
        const width = Math.min(face.bounds.width, frame.width - x);
        const height = Math.min(face.bounds.height, frame.height - y);

        if (width <= 0 || height <= 0) return;

        // ë¦¬ì‚¬ì´ì¦ˆ
        const resized = resize(frame, {
          scale: {
            width: 112,
            height: 112,
          },
          pixelFormat: 'rgb',
          dataType: 'uint8',
          crop: {
            x: x,
            y: y,
            width: width,
            height: height,
          },
        });

        // uint8 ë°ì´í„°ë¥¼ int8 ë°ì´í„°ë¡œ ë³€í™˜
        // 0~255 ë²”ìœ„ì˜ ê°’ì„ -128~127 ë²”ìœ„ë¡œ ì´ë™ (Pixel - 128)
        const inputData = new Int8Array(resized.length);
        for (let i = 0; i < resized.length; i++) {
          inputData[i] = resized[i] - 128;
        }

        // D. ëª¨ë¸ ì‹¤í–‰
        const output = model.runSync([inputData]); //

        // E. ê²°ê³¼ ì¶”ì¶œ
        const embedding = output[0];

        // E. í‚¤ ì¶”ì¶œ ì„±ê³µ ì‹œ
        if (embedding) {
          const vectorValues = Array.from(embedding as any) as number[];
          const extractedKey = vectorValues
            .slice(0, 5)
            .map((v: number) => v.toFixed(3))
            .join(', ');

          // embedding vector í™•ì¸ìš© ë¡œê·¸
          console.log(embedding);

          // í‚¤ê°€ ì¶”ì¶œë˜ì—ˆìœ¼ë©´ ì¦‰ì‹œ JSë¡œ ë³´ë‚´ê³  ë©ˆì¶¤ ìš”ì²­
          handleCaptureJS(faces, frame.width, frame.height, extractedKey);
        }
      }
    },
    [handleCaptureJS, model, resize],
  );

  // ì¬ì‹œì‘ í•¨ìˆ˜
  const resetScan = () => {
    setIsCaptured(false);
    setFaceData({faces: [], frameWidth: 0, frameHeight: 0, keyString: ''});
  };

  if (!hasPermission) return <Text>ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.</Text>;
  if (device == null) return <Text>ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤.</Text>;

  return (
    <View style={styles.container}>
      <Camera
        style={StyleSheet.absoluteFill}
        device={device}
        isActive={!isCaptured}
        frameProcessor={frameProcessor}
        pixelFormat="yuv"
        resizeMode="cover"
      />

      {faceData.faces.map((face, index) => {
        const {bounds} = face;
        const {frameWidth, frameHeight} = faceData;
        if (frameWidth === 0 || frameHeight === 0) return null;

        const sensorRotatedWidth = frameHeight;
        const sensorRotatedHeight = frameWidth;
        const scaleX = windowWidth / sensorRotatedWidth;
        const scaleY = windowHeight / sensorRotatedHeight;
        const scale = Math.max(scaleX, scaleY);

        const scaledSensorWidth = sensorRotatedWidth * scale;
        const offsetX = (scaledSensorWidth - windowWidth) / 2;
        const offsetY = (sensorRotatedHeight * scale - windowHeight) / 2;

        let finalX = bounds.y * scale - offsetX;
        let finalY = bounds.x * scale - offsetY;
        let finalWidth = bounds.height * scale;
        let finalHeight = bounds.width * scale;

        if (device.position === 'front') {
          finalX = windowWidth - finalX - finalWidth;
        }

        finalY += VERTICAL_OFFSET;
        finalX += HORIZONTAL_OFFSET;

        return (
          <View
            key={index}
            style={{
              position: 'absolute',
              borderColor: isCaptured ? '#00FFFF' : '#00FF00',
              borderWidth: 3,
              left: finalX,
              top: finalY,
              width: finalWidth,
              height: finalHeight,
              zIndex: 10,
            }}
          />
        );
      })}

      <View style={styles.infoOverlay}>
        <Text style={styles.infoTitle}>
          {isCaptured ? 'âœ… ì¸ì‹ ì™„ë£Œ (ë©ˆì¶¤)' : 'ğŸ‘¤ ì–¼êµ´ ì¸ì‹ ì¤‘...'}
        </Text>

        {isCaptured && (
          <View style={{alignItems: 'center'}}>
            <Text style={styles.infoLabel}>ì¶”ì¶œëœ í‚¤ê°’:</Text>
            <Text style={styles.infoValue}>[{faceData.keyString}, ...]</Text>

            {/* ë‹¤ì‹œ ì°ê¸° ë²„íŠ¼ */}
            <TouchableOpacity onPress={resetScan} style={styles.retryButton}>
              <Text style={styles.retryText}>ğŸ”„ ë‹¤ì‹œ ìŠ¤ìº”í•˜ê¸°</Text>
            </TouchableOpacity>
          </View>
        )}
      </View>
    </View>
  );
};

const styles = StyleSheet.create({
  container: {flex: 1, backgroundColor: 'black'},
  infoOverlay: {
    position: 'absolute',
    bottom: 50,
    left: 20,
    right: 20,
    backgroundColor: 'rgba(0,0,0,0.8)',
    padding: 20,
    borderRadius: 16,
    alignItems: 'center',
  },
  infoTitle: {
    color: 'white',
    fontSize: 20,
    fontWeight: 'bold',
    marginBottom: 10,
  },
  infoLabel: {
    color: '#aaa',
    fontSize: 12,
    marginTop: 5,
  },
  infoValue: {
    color: '#4CAF50',
    fontSize: 18,
    fontWeight: 'bold',
    textAlign: 'center',
    marginVertical: 10,
  },
  retryButton: {
    marginTop: 10,
    backgroundColor: '#2196F3',
    paddingVertical: 10,
    paddingHorizontal: 20,
    borderRadius: 8,
  },
  retryText: {
    color: 'white',
    fontWeight: 'bold',
  },
});

export default CameraComponent;
